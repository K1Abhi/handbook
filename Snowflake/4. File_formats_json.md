## üìÅ File Format Summary for Snowflake (with Examples)

| Format    | Structure          | Orientation    | Compression | Use Case                    | Supports          | Notes                                                                 |
|-----------|--------------------|----------------|-------------|-----------------------------|-------------------|-----------------------------------------------------------------------|
| **CSV**   | Tabular (flat)     | Row-oriented   | ‚ùå           | Transactions, logs          | ‚úÖ Load & Unload   | Delimiter-based (comma, tab, etc). No data types. Simple and common. |
| **JSON**  | Semi-structured    | Hierarchical   | Optional     | Logs, web events            | ‚úÖ Load & Unload   | Flexible schema. NDJSON = 1 JSON object per line.                    |
| **XML**   | Semi-structured    | Hierarchical   | Optional     | Legacy/Enterprise data      | ‚úÖ Load only        | Verbose, tag-based. Common in older systems.                         |
| **PARQUET**| Tabular (binary)  | Column-oriented| ‚úÖ           | Analytics, large datasets   | ‚úÖ Load & Unload   | Optimized for selecting specific columns. Used in Hadoop.            |
| **ORC**   | Tabular (binary)   | Column-oriented| ‚úÖ           | Analytics, Hive integration | ‚úÖ Load only        | High compression and performance.                                    |
| **AVRO**  | Semi-tabular       | Row-oriented   | ‚úÖ           | Streaming, schema evolution | ‚úÖ Load only        | Includes schema in JSON. Great for Kafka and RPCs.                   |

---

### Examples

#### 1. **CSV (Comma-Separated)**
```csv
id,name,amount
1,Alice,100
2,Bob,200
```
#### 2. NDJSON (Newline-Delimited JSON)

```json
{"id": 1, "name": "Alice", "amount": 100}
{"id": 2, "name": "Bob", "amount": 200}
```

#### 3. XML
```xml
<transactions>
  <transaction><id>1</id><name>Alice</name><amount>100</amount></transaction>
  <transaction><id>2</id><name>Bob</name><amount>200</amount></transaction>
</transactions>
```
#### 4.PARQUET
> Binary format ‚Äî can't be directly represented in plain text, but contains the same data as CSV or JSON.

Optimized for columnar queries like:
```sql
SELECT amount FROM transactions;
```

#### 5.ORC
> Similar to Parquet, binary and column-oriented. Used in Hive/Presto environments.

#### 6. AVRO
> Includes schema metadata in JSON format (used for deserialization)

```json
{
  "type": "record",
  "name": "Transaction",
  "fields": [
    {"name": "id", "type": "int"},
    {"name": "name", "type": "string"},
    {"name": "amount", "type": "float"}
  ]
}
```
> üìù**Tip**:
- High-performance analytics, prefer columnar formats like **Parquet** or **ORC**.
- For logs and semi-structured data, use **JSON** or **NDJSON**.
- For simple interoperability, **CSV** is still widely used.

---
## üì• Loading JSON Data into Snowflake

Snowflake supports loading semi-structured JSON data into **`VARIANT`** columns. Here's a practical workflow for working with JSON.

### 1. Create a JSON File Format

Before loading the data, define a file format that tells Snowflake how to interpret the file.

```sql
CREATE OR REPLACE FILE FORMAT myjsonformat 
  TYPE = 'JSON';
```


### 2. Try Inferring Schema (Optional for Inspection)
```sql
SELECT *
FROM TABLE(INFER_SCHEMA(
  LOCATION => '@mystage',
  FILES => ('dept.json'),
  FILE_FORMAT => 'myjsonformat'));
```
#### Output 
| COLUMN\_NAME | TYPE  | NULLABLE | EXPRESSION       | FILENAMES | ORDER\_ID |
| ------------ | ----- | -------- | ---------------- | --------- | --------- |
| data         | ARRAY | true     | `$1:data::ARRAY` | dept.json | 0         |

> The output indicates the JSON root element is an object with a key "data" holding an array ‚Äî not directly usable yet.
> By default, `INFER_SCHEMA` just treats JSON as a nested `ARRAY`, which is not helpful for directly extracting fields.

### 3. Create a Temporary Table with `VARIANT`
You need a table to hold the raw `JSON`. Since we are doing exploratory analysis or ETL prep, use a temporary table to avoid affecting Time Travel or storage.
```sql
CREATE TEMPORARY TABLE deptt(v VARIANT);
```
> Temp tables are dropped at session end.
> We can also use TRANSIENT tables if the table should persist across sessions but avoid Time Travel charges.

### 4. Load JSON Data into Snowflake
Now load your file (e.g., `dept.json` from stage `@mystage`) into the `VARIANT` column:

```sql
COPY INTO deptt
  FROM @mystage
  FILES = ('dept.json')
  FILE_FORMAT = (FORMAT_NAME = myjsonformat)
  FORCE = TRUE;
```
> `FORCE = TRUE` ensures files are reloaded even if they were previously loaded.

### 5. Explore the Loaded Data
Once loaded, the entire JSON object appears as a single `VARIANT` cell:
```sql
SELECT * FROM deptt;
```
#### Output 
```json
{
  "data": [
    {
      "DEPTNO": 10,
      "DNAME": "ACCOUNTING",
      "LOC": "NEW YORK"
    },
    {
      "DEPTNO": 20,
      "DNAME": "RESEARCH",
      "LOC": "DALLAS"
    },
    {
      "DEPTNO": 30,
      "DNAME": "SALES",
      "LOC": "CHICAGO"
    },
    {
      "DEPTNO": 40,
      "DNAME": "OPERATIONS",
      "LOC": "BOSTON"
    }
  ]
}
```
To extract rows from the nested array, we will need to use `FLATTEN` and `SELECT` on the JSON structure ‚Äî this is typically done after verifying data was loaded correctly.
