# Snowpark 

## What is Snowpark?
Snowpark is a client-side library, not a server-side engine or tool. It allows you to write code (especially in Python, Java, or Scala) that executes within Snowflake, close to the data. The main goal is to push business logic to where the data lives inside Snowflakeâ€™s compute infrastructure so we donâ€™t need to move large amounts of data back and forth between client and server.

## Why is there a push for Snowpark?
- Snowflake initially supported stored procedures (SPs) with:
  - Only single SQL statements
  - And JavaScript (which was clunky for complex pipelines)
- Then came **Snowflake Scripting** (like PL/SQL or T-SQL), which allowed procedural SQL blocks.
- Now, Snowpark takes it a step further:
  - Let you define complex business logic (e.g., data transformations) using DataFrame APIs and Python functions
  - All while keeping the processing inside Snowflake, without pulling the data to a client

## Client vs. Server Execution
- Traditionally, logic would run on your local machine or cloud VM, connecting to Snowflake and pulling data to process.
- With Snowpark, we instead send your logic to Snowflake, and itâ€™s executed on the same infrastructure where our data lives.
- This reduces latency, cost, and bandwidth usage.

![image](https://github.com/user-attachments/assets/b4cf48f2-74a3-46ae-83f8-880435d0c968)

##  Snowflakeâ€™s Goal with Snowpark 
Snowflake aims to turn its compute layer into a hybrid of:
- Database Server (as usual), and
- Application Server (by supporting business logic natively)
They already support:
- SQL scripting (procedures, loops, conditions)
- Java/Scala Snowpark functions (because Snowflake is built on Scala)
- Python Snowpark code (via sandboxed virtual environments)


## Snowpark for Python


![image](https://github.com/user-attachments/assets/b04acc1a-ab26-42cc-9dae-72806c4c83f5)
Two key capabilities:   
**1. DataFrame API**
- Works like Pandas or PySpark: you chain functions to build transformations.
- Uses lazy evaluation: queries only run when you call .collect(), .show(), etc.
- Behind the scenes, the DataFrame query is translated to SQL and executed by Snowflakeâ€™s SQL engine.

**2. Python Functions for Server Execution**
You can write:
- **Stored Procedures:** can run SQL and use logic (loops, API calls, etc.)
- **UDFs (User-Defined Functions):** used in SQL queries for row-level operations.
- **UDTFs (User-Defined Table Functions):** used when your function returns a table (multiple rows).

This Python code is:
- Serialized and sent to Snowflakeâ€™s virtual machines
- Executed in a sandboxed Python environment
- Can use:
  - Pre-installed Anaconda packages
  - Or your own packages, uploaded to a stage (like cloud storage)

### How it All Works â€“ Under the Hood
- You build your logic using Snowparkâ€™s Python library
- When executed:
  1. The DataFrame logic is translated to SQL via the Python connector
  2. The Python code (UDF/SP) is serialized, transferred, and executed in the Snowflake Python sandbox
  3. Optional packages can be preloaded (Anaconda) or user-supplied (via stages)

![image](https://github.com/user-attachments/assets/d63737a4-a69a-4d61-8f3c-4acde43ee681)


### Why Use Snowpark?
- Avoids moving data between client and Snowflake
- Reduces latency and cost
- Enables complex business logic in Python
- Fully integrates with Snowflakeâ€™s compute and security layers
- Empowers data engineers and scientists to work more effectively inside Snowflake itself

## Create Query with DataFrame API

### Traditional Snowflake Connector Approach (Pandas)
Use `snowflake.connector.connect()` with parameters like account, user, password, database, and schema.    
Execute an SQL query using `pandas.read_sql(sql, conn)`:
```sql
SELECT dname, SUM(sal)
FROM emp JOIN dept ON emp.deptno = dept.deptno
WHERE dname <> 'RESEARCH'
GROUP BY dname
ORDER BY dname;
```

This returns a **Pandas DataFrame** that displays department names and total salaries (excluding "RESEARCH").

### ðŸ“¢ Transition to Snowpark 
- **Introduce Snowpark:** A powerful way to write SQL queries programmatically using a functional API style.
- Connect using a `Session.builder` object instead of `connect()`:
```python
from snowflake.snowpark import Session

pars = {
    "account": "XLB86271",
    "user": "cscutaru",
    "password": os.environ["SNOWSQL_PWD"],
    "database": "EMPLOYEES",
    "schema": "PUBLIC"
}
session = Session.builder.configs(pars).create()
```
### **Building the Query with Snowpark DataFrame API**
1. Load employee and department tables:
   ```python
   emps = session.table("EMP").select("DEPTNO", "SAL")
   depts = session.table("DEPT").select("DEPTNO", "DNAME")
   ```
2. Perform a **join:**
   ```python
   q = emps.join(depts, emps.deptno == depts.deptno)
   ```
3. Apply a **filter:**
   ```python
   q = q.filter(q.dname != 'RESEARCH')
   ```
4. Perform **aggregation** and **sorting**:
   ```python
     (q.select("DNAME", "SAL")
    .group_by("DNAME")
    .agg({"SAL": "sum"})
    .sort("DNAME")
    .show())
   ```

### Code Comparison

**1. Using Pandas**
```python
    sql = """
    select dname, sum(sal)
      from emp join dept on emp.deptno = dept.deptno
      where dname <> 'RESEARCH'
      group by dname
      order by dname;
    """
    df = pd.read_sql(sql, conn)
    print(df)
```
**2. Using Snowpark**
```python
emps = session.table("EMP").select("DEPTNO", "SAL")
depts = session.table("DEPT").select("DEPTNO", "DNAME")
q = emps.join(depts, emps.deptno == depts.deptno)
q = q.filter(q.dname != 'RESEARCH')
(q.select("DNAME", "SAL")
  .group_by("DNAME")
  .agg({"SAL": "sum"})
  .sort("DNAME")
  .show())
```

### Important Points 
**Lazy Evaluation:**    
- The DataFrame API builds the query in memory as a logical plan.
- No data is transferred until an action like `.show()` or `.collect()` is called.
- Only then is a **single SQL query generated and pushed to the Snowflake server**.
**Generated SQL:**
A complex SQL statement is auto-generated (visible in Snowflakeâ€™s Query History).
- Example includes subqueries, joins, filters, and LIMIT 10 added by default when calling .show().
