
## â„ï¸ Snowflake Data Pipelines 

### Scenario 1: Real-Time Table Syncing via Change Data Capture (CDC)

#### Use Case
- A `customers` table is owned by an external department.
- Need to maintain an up-to-date copy in our Snowflake database.
- Sync should reflect all changes in **near real-time**.

#### Solution Overview
- Use **Change Data Capture (CDC)** to handle incremental updates.

#### Methods for Implementing CDC in Snowflake
1. **MERGE Statement**
   - SQL command to upsert records into a target table.
2. **Change Tracking**
   - Allows tracking changes on a table without capturing the actual data.
3. **Streams and Tasks**
   - Earlier method to automate CDC workflows.
4. **Dynamic Tables**
   - New and simplified approach to manage incremental data changes.

---

### Scenario 2: Automated CSV Ingestion via Snowpipe

#### Use Case
- New employee records are added using CSV files dropped into an **Amazon S3 bucket**.
- Only insertions are allowed (no updates or deletions).

#### Solution Overview
- Use **Snowpipe** to automate CSV ingestion.

#### Components Involved
- **External Stage**: Connects Snowflake to the S3 bucket.
- **Snowpipe**: Automates continuous data loading from S3 into Snowflake.

---

### Summary

| Requirement                       | Solution                             |
|-----------------------------------|--------------------------------------|
| Sync external table in real-time  | Change Data Capture (CDC)            |
| Handle inserts via CSV in S3      | Snowpipe + External Stage (S3)       |

> These approaches help build robust, scalable, and near real-time data pipelines in Snowflake.
---
## Batch & Stream Data Transfer

## Overview

How to implement **batch and streaming data ingestion** from a transactional source system (typically OLTP) into Snowflake using **Change Data Capture (CDC)**.
## Typical Pipeline Flow

![image](https://github.com/user-attachments/assets/161ada8f-7a97-491a-9dc5-05ae763a503f)

1. **Initial Full Batch Transfer**
   - One-time full data load from the source database to Snowflake.
   - May take significant time depending on table size.

2. **Enable CDC on Source Database**
   - Supported by databases like PostgreSQL, Oracle, SQL Server, SAP, etc.
   - Captures changes (INSERTs, UPDATEs, DELETEs) in a **CDC log**.

3. **Periodic CDC Log Transfer**
   - A data transfer tool (e.g., **Fivetran, Airbyte, Stitch**) reads CDC logs.
   - These are loaded into a **stage table** in Snowflake.
   - Each record reflects an incremental change.
## Example Workflow
- **Stage Table** receives CDC records:
  - **Inserts**: New records.
  - **Updates**: Shown as DELETE of old + INSERT of new.
  - **Deletes**: Marked with a `DEL` flag.

---
### Illustration Example:
![image](https://github.com/user-attachments/assets/996a54c4-e3f7-44e2-abc2-2787aed81253)
- Stage Table:
  - Initial: 3 inserts (new records) 1st operation.
  - Next: 2 more rows (1 update to name, 1 delete marked via flag).
---

## Applying Changes in Snowflake

The core challenge: **How to reflect stage table changes into the target snapshot table.**

### CDC Methods in Snowflake:

1. **Manual Merge Statements**
   - Use a **stored procedure** to encapsulate a `MERGE` statement.
   - Applies changes from stage to target table.

2. **Change Tracking**
   - Enables tracking of changes at the table level.
   - Captures changes to be applied elsewhere.

3. **Streams and Tasks** *(Older Approach)*
   - **Stream** detects changes.
   - **Task** runs periodically and checks if `SYSTEM$STREAM_HAS_DATA`.
   - If changes exist, runs `MERGE` using metadata fields like `METADATA$ACTION`.

4. **Dynamic Tables** *(Modern & Recommended)*
   - Replaces streams and tasks.
   - Automatically manages incremental changes and updates to the target table.

---

## Summary Table

| Step                        | Description |
|-----------------------------|-------------|
| Initial Batch Load          | One-time full data transfer |
| CDC Log Capture             | Source DB logs changes |
| CDC Log Ingestion           | Transfer tools push changes to Snowflake |
| Change Application Methods  | Manual Merge, Change Tracking, Streams & Tasks, Dynamic Tables |

> Modern Snowflake CDC is best implemented using **Dynamic Tables** for simplicity and automation.



## ðŸ› ï¸ Manual CDC in Snowflake using MERGE and Stored Procedures âš™ï¸

This walkthrough demonstrates a **manual Change Data Capture (CDC)** process in Snowflake using a stage (`source`) table and a `target` table. The CDC is implemented via a `MERGE` statement and encapsulated in a stored procedure.

### âš’ï¸ Setup

#### 1. Create Database and Schema

```sql
CREATE DATABASE IF NOT EXISTS data_pipelines;
CREATE OR REPLACE SCHEMA data_pipelines.manual_cdc;
```

### ð„œ Create Tables

#### 2. Source and Target Tables

```sql
CREATE TABLE source (
  del BOOLEAN, 
  id INT, 
  name STRING
);

CREATE TABLE target (
  id INT, 
  name STRING
);
```

### ðŸ—‚ï¸ CDC Merge Logic

#### 3. MERGE Statement

```sql
MERGE INTO target t 
USING source s 
ON t.id = s.id
WHEN NOT MATCHED AND NOT del THEN 
  INSERT (id, name) VALUES (s.id, s.name)
WHEN MATCHED AND del THEN 
  DELETE
WHEN MATCHED AND NOT del THEN 
  UPDATE SET t.name = s.name;
```

### â© Stored Procedure for CDC

#### 4. Create Procedure

```sql
CREATE PROCEDURE cdc() RETURNS INT
AS $$
MERGE INTO target t USING source s ON t.id = s.id
  WHEN NOT MATCHED AND NOT del THEN 
    INSERT (id, name) VALUES (s.id, s.name)
  WHEN MATCHED AND del THEN 
    DELETE
  WHEN MATCHED AND NOT del THEN 
    UPDATE SET t.name = s.name;
$$;
```

### Test the Manual CDC

#### 5. Initial Inserts (3 rows)

```sql
INSERT INTO source VALUES (False, 1, 'John'), 
                         (False, 2, 'Mary'), 
                         (False, 3, 'George');

CALL cdc();
TRUNCATE TABLE source;
SELECT * FROM target;
```

Expected Result:
```
+----+--------+
| ID | NAME   |
+----+--------+
| 1  | John   |
| 2  | Mary   |
| 3  | George |
+----+--------+
```

#### 6. Update and Delete Test

```sql
-- ID 1: Update to 'Mark'
-- ID 2: Delete
INSERT INTO source VALUES (False, 1, 'Mark'), 
                         (True, 2, NULL);

CALL cdc();
TRUNCATE TABLE source;
SELECT * FROM target;
```

Expected Result:
```
+----+--------+
| ID | NAME   |
+----+--------+
| 1  | Mark   |
| 3  | George |
+----+--------+
```

### Notes

- `del` flag is used in the `source` table to indicate delete operations.
- Snowflake does **not enforce primary keys**, so logical uniqueness is assumed by `id`.
- This MERGE-based CDC is often encapsulated in procedures for easier scheduling and orchestration.
---

## Snowflake CDC using CHANGE_TRACKING ðŸ“ˆ

#### Scenario
You have a typical snapshot table (no `del_flag`, no audit columns), and you want to emit all incremental changes `(INSERTs, UPDATEs, DELETEs)` from it.
Snowflake's `CHANGE_TRACKING` makes this possible without modifying the table schema.

##### 1. Set up the database and schema:
```sql
CREATE DATABASE IF NOT EXISTS data_pipelines;
CREATE OR REPLACE SCHEMA data_pipelines.change_tracking;
```
##### 2.Create a snapshot-style source table and enable change tracking:
```sql
CREATE OR REPLACE TABLE source(id INT, name STRING);
ALTER TABLE source SET CHANGE_TRACKING = TRUE;
```
##### 3.Capture a reference timestamp before changes:
```sql
SET ts1 = (SELECT CURRENT_TIMESTAMP());
```
##### 4. Perform data changes
```sql
-- Initial inserts
INSERT INTO source VALUES (1, 'John'), (2, 'Mary'), (3, 'George');

-- Update and delete
UPDATE source SET name = 'Mark' WHERE id = 1;
DELETE FROM source WHERE id = 2;
```
##### 5. Track and query changes:
- Only new inserts (append-only):
  ```sql
  SELECT * FROM source
  CHANGES (INFORMATION => APPEND_ONLY) AT (TIMESTAMP => $ts1);
  ```
- All changes (insert, update, delete):
  ```sql
  SELECT * FROM source
  CHANGES (INFORMATION => DEFAULT) AT (TIMESTAMP => $ts1);
  ```
  This result includes:
   - Metadata columns: _CHANGE_TYPE, _CHANGE_TIMESTAMP, _ROW_ID
   - `I = Insert`, `U = Update`, `D = Delete`

##### 6. Create a target table reflecting the current state from that point forward:
```sql
CREATE OR REPLACE TABLE target AS
  SELECT id, name FROM source
  CHANGES (INFORMATION => DEFAULT) AT (TIMESTAMP => $ts1);

SELECT * FROM target;
```

> Even if your source table doesnâ€™t have audit columns or flags, you can still track all incremental changes using Snowflakeâ€™s `CHANGE_TRACKING` feature by simply enabling it and using the `CHANGES` clause in queries.


